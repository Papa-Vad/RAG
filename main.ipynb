{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53d0cf78",
      "metadata": {
        "id": "53d0cf78"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a1bb89e",
      "metadata": {
        "id": "4a1bb89e"
      },
      "outputs": [],
      "source": [
        "import docx\n",
        "import spacy\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# Load spaCy Russian tokenizer\n",
        "nlp = spacy.blank(\"ru\")\n",
        "\n",
        "# Load a pre-trained model tokenizer and model from Hugging Face transformers\n",
        "model_name = \"bert-base-multilingual-cased\"  # Pre-trained multilingual BERT model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "def read_docx(file_path):\n",
        "    # Open the Word document\n",
        "    doc = docx.Document(file_path)\n",
        "\n",
        "    # Extract text content from the document\n",
        "    full_text = []\n",
        "    for para in doc.paragraphs:\n",
        "        full_text.append(para.text)\n",
        "\n",
        "    # Join all paragraphs into a single string\n",
        "    document_text = \"\\n\".join(full_text)\n",
        "    return document_text\n",
        "\n",
        "def chunk_and_encode_document(document_text, max_chunk_len=200):\n",
        "    # Split the document into chunks\n",
        "    doc = nlp(document_text)\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "\n",
        "    for token in doc:\n",
        "        if len(current_chunk) + len(token.text) > max_chunk_len:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            current_chunk = []\n",
        "\n",
        "        current_chunk.append(token.text)\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    # Encode each chunk into vectors\n",
        "    encoded_chunks = []\n",
        "\n",
        "    for chunk in chunks:\n",
        "        # Tokenize the chunk\n",
        "        inputs = tokenizer(chunk, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "        # Pass the input through the model and get the hidden states\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Extract the embeddings (CLS token embedding)\n",
        "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        # Normalize the embeddings\n",
        "        normalized_embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "        # Append the normalized embedding to the list\n",
        "        encoded_chunks.append(normalized_embeddings)\n",
        "\n",
        "    return chunks, encoded_chunks\n",
        "\n",
        "# Example usage\n",
        "file_path = \"main_doc.docx\"\n",
        "document_text = read_docx(file_path)\n",
        "chunks, encoded_chunks = chunk_and_encode_document(document_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8d5490d",
      "metadata": {
        "id": "f8d5490d",
        "outputId": "38f79915-7357-4640-bc71-f4bebf95c6d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closest chunks to the query:\n",
            "chunk  1\n",
            "\n",
            "1. рассчитывается только после повторной сдачи таких Элементов . Порядок организации таких повторных сдач отражается в ПУД . Повторные сдачи по таким блокирующим Элементам проводятся по КИМам и технологии , аналогичным применяемым при первом проведении этого Элемента контроля . Порядок проведения таких повторных сдач во время сессии в случае потенциального конфликта с основным расписанием сессии регулируется пунктом 57 Положения . \n",
            " Если у студента возникает неудовлетворительная оценка по Элементу контроля по Дисциплине , то она не может быть причиной недопуска к следующим Элементам контроля ( включая экзамены ) по этой Дисциплине , проводимым до окончания ближайшей сессии , в которую предусмотрена промежуточная аттестация по этой Дисциплине . \n",
            " Преподаватель имеет право незначительно корректировать количество и процедуры организации Элементов контроля . В этом случае он должен зафиксировать изменения в ПУД посредством Конструктора ПУД и отдельно проинформировать студентов об изменениях и их причинах . Информирование осуществляется не позднее трёх учебных дней до начала проведения Элемента контроля , не являющегося экзаменом , в отношении которого произошли изменения . Не позднее трех учебных дней с момента информирования студент имеет право обратиться к академическому руководителю своей образовательной программы с уведомлением об изменениях . Академический руководитель в данной ситуации\n",
            "\n",
            "chunk  2\n",
            "\n",
            "2. искусственного интеллекта » . Оценка , выставленная автоматическим алгоритмом , может быть перепроверена и пересмотрена рабочей группой . \n",
            " Оценки доводятся до студентов не позднее , чем 30 марта и 30 июня соответственно ( см . п . 1.7 ) . \n",
            " Апелляция \n",
            " Апелляция к НЭ по ЦК не предусмотрена . \n",
            " В случаях технических проблем и сбоев в работе бланка при проведении НЭ по ЦК студент имеет право направить мотивированное заявление в учебный офис своей образовательной программы по корпоративной почте , а также через автоматизированный сервис в ЭИОС до 23.59 непосредственно в день проведения НЭ по ЦК с описанием технических сбоев в работе бланка с приложением подтверждающих материалов ( скриншота экрана , включающего системное время создания скриншота/ фото , видео и т.д . ) . \n",
            " В случае удовлетворения мотивированного заявления , поданного в учебный офис , работа студента аннулируется , и ему предоставляется возможность написать НЭ по ЦК в резервный день . \n",
            " Студент должен за 2 рабочих дня до установленного периода резервных дней подать в учебный офис заявку на сдачу НЭ по ЦК в резервный день . Учебный офис регистрирует студента на НЭ по ЦК в резервный день . \n",
            " Не\n",
            "\n",
            "chunk  3\n",
            "\n",
            "3. Секретарь ГЭК объявляет оценки членам ГЭК . \n",
            " Оценка , полученная студентом на защите Project Proposal , указывается отдельной строкой в приложении к диплому выпускника бакалавриата и специалитета НИУ ВШЭ . \n",
            " В случае изменения темы ВКР студента , который восстанавливается для повторного прохождения государственной итоговой аттестации , предполагающей подготовку содержательно нового текста ВКР , в ИУП студента включается обязательная защита Project Proposal даже в случае , если до отчисления по данному элементу учебного плана студентом была получена положительная оценка . \n",
            "\n",
            " Практическая подготовка \n",
            " Оценки за элементы практической подготовки ( далее – ЭПП ) , выставляются в ведомость либо в оценочный лист . Оформление ведомости по ЭПП допускается при наличии более чем 20 студентов , реализующих ЭПП , либо по согласованию с академическим руководителем образовательной программы . Ведомости с оценками и оценочные листы подписываются руководителями ЭПП и сдаются в учебный офис не позднее окончания сессии . Если окончание ЭПП не совпадает с окончанием модуля по календарному учебному графику , ведомости или оценочные листы по ЭПП должны быть предоставлены в учебный офис не позднее 5 рабочих дней после даты окончания ЭПП . Если ЭПП проводится в летний период , то ведомость или\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def encode_query(query_text):\n",
        "    # Encode the query text into a vector\n",
        "    inputs = tokenizer(query_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Extract the embeddings (CLS token embedding)\n",
        "    query_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "    # Normalize the embedding\n",
        "    normalized_query_embedding = torch.nn.functional.normalize(query_embedding, p=2, dim=1)\n",
        "\n",
        "    return normalized_query_embedding\n",
        "\n",
        "\n",
        "\n",
        "def vector_search(query_embedding, encoded_chunks, chunks):\n",
        "    # Compute cosine similarity between query embedding and all chunk embeddings\n",
        "    similarities = []\n",
        "\n",
        "    for emb in encoded_chunks:\n",
        "        sim = cosine_similarity(query_embedding.numpy().reshape(1, -1), emb.numpy().reshape(1, -1))\n",
        "        similarities.append(sim.item())\n",
        "\n",
        "    # Find indices of the top 3 most similar chunks\n",
        "    closest_indices = np.argsort(similarities)[::-1][:3]\n",
        "    closest_chunks = [chunks[idx] for idx in closest_indices]\n",
        "\n",
        "    return closest_chunks\n",
        "\n",
        "\n",
        "\n",
        "query = 'Какова роль академического руководителя в НИУ ВШЭ?'\n",
        "query_embedding = encode_query(query)\n",
        "closest_chunks = vector_search(query_embedding, encoded_chunks, chunks)\n",
        "i=1\n",
        "print(\"Closest chunks to the query:\")\n",
        "for idx, chunk in enumerate(closest_chunks, start=1):\n",
        "    print('chunk ',i)\n",
        "    print()\n",
        "    i+=1\n",
        "    print(f\"{idx}. {chunk}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5af8bf95",
      "metadata": {
        "id": "5af8bf95",
        "outputId": "8b4efe33-b61f-4d23-f954-e86d799e4a87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"result\":{\"alternatives\":[{\"message\":{\"role\":\"assistant\",\"text\":\"Для написания любой работы, включая работу на соискание степени LLM (магистра права), необходимо следовать определённым стандартам и требованиям, которые могут различаться в зависимости от учебного заведения и программы. Вот некоторые общие рекомендации, которые могут вам помочь:\\n1. **Определите тему и фокус вашей работы.** LLM-программы обычно требуют глубокого анализа и исследования в определённой области права. Тема должна быть актуальной и соответствовать вашей области специализации.\\n\\n2. **Определите цель и задачи работы.** Что вы хотите достичь в своей работе? Какие вопросы вы хотите рассмотреть? Это поможет вам организовать структуру и содержание вашей работы.\\n3. **Проведите исследование.** Соберите информацию из различных источников, таких как книги, статьи, юридические прецеденты и другие релевантные материалы. Убедитесь, что вы используете надёжные и авторитетные источники.\\n4. **Разработайте план работы.** Определите структуру вашей работы, которая может включать введение, несколько глав, заключение и список литературы. В каждой главе представьте основные тезисы и аргументы, подкреплённые соответствующими источниками.\\n5. **Напишите текст работы.** Следуйте логике и структуре вашего плана. Используйте ясный и структурированный стиль изложения, избегайте двусмысленности и неопределённости. Поддерживайте баланс между анализом и аргументацией, а также между теоретическими и практическими аспектами.\\n6. **Оформите работу в соответствии с требованиями.** Следуйте формату, стилю и структуре, установленным вашим учебным заведением. Это может включать форматирование, структуру страниц, оформление ссылок и списка литературы.\\n7. **Подготовьте презентацию.** Если это требуется вашей программой, подготовьте презентацию, чтобы представить вашу работу перед комиссией.\\n8. **Рецензирование и редактирование.** Попросите других специалистов просмотреть вашу работу и дать конструктивную критику. Исправьте обнаруженные ошибки и улучшите качество вашей работы.\\n9. **Подача и защита.** Подготовьтесь к защите вашей работы перед комиссией, предоставьте ответы на возможные вопросы и убедительно защищайте свои аргументы.\\n10. **После защиты.** После успешной защиты продолжайте развивать свои знания и навыки в выбранной области права, так как это поможет вам стать успешным специалистом.\\nПомните, что требования и стандарты могут меняться в зависимости от вашего учебного заведения и уровня LLM. Рекомендуется консультироваться с преподавателями и руководством программы для получения более точных рекомендаций и поддержки.\"},\"status\":\"ALTERNATIVE_STATUS_FINAL\"}],\"usage\":{\"inputTextTokens\":\"29\",\"completionTokens\":\"464\",\"totalTokens\":\"493\"},\"modelVersion\":\"18.01.2024\"}}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "prompt = {\n",
        "    \"modelUri\": \"gpt://b1g91rv9466rln6hv7lr/yandexgpt-lite\",\n",
        "    \"completionOptions\": {\n",
        "        \"stream\": False,\n",
        "        \"temperature\": 0.6,\n",
        "        \"maxTokens\": \"2000\"\n",
        "    },\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"text\": \"ты умный помошник студента\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"text\": \"Привет,......?\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "url = \"https://llm.api.cloud.yandex.net/foundationModels/v1/completion\"\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": \"________________________\"\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, json=prompt)\n",
        "result = response.text\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbcf1696",
      "metadata": {
        "id": "bbcf1696"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}